{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4542e2a7-e675-47de-afd5-f72d639c14ff",
   "metadata": {},
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddaf265-6086-40fe-8dc1-6e843a9e5fe9",
   "metadata": {},
   "source": [
    "## Ex.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3a7c34-b0e4-46a0-83fb-31cb6a1fc57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf762cf-cded-4716-8938-6bd362d527e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum did not validate. Try again.\n",
      "         dates     hours  temps  hums\n",
      "0   04/11/2021  17:16:32     20    40\n",
      "1   04/11/2021  17:16:39     20    41\n",
      "2   04/11/2021  17:16:45     21    40\n",
      "3   04/11/2021  17:16:51     21    40\n",
      "4   04/11/2021  17:16:57     21    40\n",
      "5   04/11/2021  17:17:04     21    40\n",
      "6   04/11/2021  17:17:10     21    40\n",
      "7   04/11/2021  17:17:16     21    39\n",
      "8   04/11/2021  17:17:22     21    39\n",
      "9   04/11/2021  17:17:29     21    39\n",
      "10  04/11/2021  17:17:35     21    39\n",
      "11  04/11/2021  17:17:41     21    39\n",
      "12  04/11/2021  17:17:47     21    39\n",
      "13  04/11/2021  17:17:54     21    39\n",
      "14  04/11/2021  17:18:00     21    39\n",
      "15  04/11/2021  17:18:06     21    39\n",
      "16  04/11/2021  17:18:12     21    39\n",
      "17  04/11/2021  17:18:19     21    39\n",
      "18  04/11/2021  17:18:25     21    39\n",
      "19  04/11/2021  17:18:31     21    39\n",
      "20  04/11/2021  17:18:38     21    39\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import board\n",
    "import adafruit_dht\n",
    "import psutil\n",
    "\n",
    "import datetime \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# We first check if a libgpiod process is running. If yes, we kill it!\n",
    "for proc in psutil.process_iter():\n",
    "    if proc.name() == 'libgpiod_pulsein' or proc.name() == 'libgpiod_pulsei':\n",
    "        proc.kill()\n",
    "\n",
    "sensor = adafruit_dht.DHT11(board.D4)\n",
    "\n",
    "frequency = 6\n",
    "period = 120\n",
    "\n",
    "dates = []\n",
    "hours = []\n",
    "hums = []\n",
    "temps = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "while count <= int(period/frequency):\n",
    "    try:\n",
    "        temp = sensor.temperature\n",
    "        humidity = sensor.humidity\n",
    "        date = datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        dates.append(date.split(\" \")[0])\n",
    "        hours.append(date.split(\" \")[1])\n",
    "\n",
    "        temps.append(temp)\n",
    "        hums.append(humidity)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    except RuntimeError as error:\n",
    "        print(error.args[0])\n",
    "        \n",
    "        continue\n",
    "\n",
    "    time.sleep(frequency)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'dates':dates,'hours':hours, 'temps':temps, 'hums':hums})\n",
    "print(df)\n",
    "df.to_csv('dataset_ex1.csv', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2b66c-215c-4757-9f6a-a4ee437a36ba",
   "metadata": {},
   "source": [
    "## Ex.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c34ba-8116-47d0-8135-c6669c1d4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pyaudio package to drive the microphone \n",
    "# (with the blocking mode) and the wave package to \n",
    "# store the samples on disk.\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "import os\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "def record_audio(args):\n",
    "\n",
    "    # define pyaudio object\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # define the format\n",
    "    if args.format == 'Int8':\n",
    "        format = pyaudio.paInt8\n",
    "    elif args.format == 'Int16':\n",
    "        format = pyaudio.paInt16\n",
    "    elif args.format == 'Int32':\n",
    "        format = pyaudio.paInt32\n",
    "\n",
    "    # open stream\n",
    "    stream = p.open(format=format, channels=args.channels, rate=args.rate, input=True, frames_per_buffer=args.chunk)\n",
    "\n",
    "\n",
    "    # record for the given amount of time\n",
    "    print(\"Start recording\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0,int(args.rate / args.chunk * args.seconds)):\n",
    "        data = stream.read(args.chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "    print(\"End recording\")\n",
    "\n",
    "    # stop the stream and close it\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # terminate pyaudio's object\n",
    "    p.terminate()\n",
    "\n",
    "    # set the filename\n",
    "    if args.name == None:\n",
    "        # concatenate the values\n",
    "        FILENAME = \"{}_{}Hz_{}s.wav\".format(args.format, args.rate, args.seconds)\n",
    "\n",
    "\n",
    "    # overwrite the file if it is already present\n",
    "    # - workaround : delete it\n",
    "    if FILENAME in os.listdir():\n",
    "        os.remove(FILENAME)\n",
    "\n",
    "\n",
    "    # setup the final audio file and save it\n",
    "    wf = wave.open(FILENAME, 'wb')\n",
    "    wf.setnchannels(args.channels)\n",
    "    wf.setsampwidth(p.get_sample_size(format))\n",
    "    wf.setframerate(args.rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "\n",
    "# close write_file's object\n",
    "    wf.close()\n",
    "\n",
    "    print(\"File salved\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--chunk', type=int, default=1024, help='Set number of chunks')\n",
    "    parser.add_argument('--format', type=str, default='Int16', help='Set the format of the audio track [Int8,Int16,Int32]')\n",
    "    parser.add_argument('--channels', type=int, default=2, help='Set the number of channels')\n",
    "    parser.add_argument('--seconds', type=int, default=3, help='Set the length of the recording (seconds)')\n",
    "    parser.add_argument('--rate', type=int, default=44100, help='Set the rate')\n",
    "    parser.add_argument('--name', type=str, default=None, help='Set the name of the audio track')\n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    record_audio(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff31b2-fa7a-45b5-a701-87fb35e41f38",
   "metadata": {},
   "source": [
    "# Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97ffec-364a-4623-bf06-acacfea71596",
   "metadata": {},
   "source": [
    "## Ex 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68867f9-7b47-48c2-b1a8-9f28fdb131ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time is: 1206.8890000000001\n",
      "889422\n",
      "96044\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "rate, audio = wavfile.read('audio2.wav')\n",
    "audio = signal.resample_poly(audio, 1, 16000)\n",
    "\n",
    "b = datetime.datetime.now()\n",
    "\n",
    "delta = b-a\n",
    "\n",
    "print(\"The total time is:\", (delta.total_seconds() * 1000)) \n",
    "\n",
    "audio = audio.astype(np.int16)\n",
    "samplerate = 48000; fs = 16000\n",
    "t = np.linspace(0., 1., samplerate)\n",
    "amplitude = np.iinfo(np.int16).max\n",
    "data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "wavfile.write(\"ex.wav\",48000,data.astype(np.int16))\n",
    "print(os.path.getsize(\"audio2.wav\"))\n",
    "print(os.path.getsize(\"ex.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d3c5d-a6f8-417b-8e33-7762adf6f1fa",
   "metadata": {},
   "source": [
    "## Ex.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6479c1-4e52-4333-ad57-07e6751c5d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time is: 1.827\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "audio = tf.io.read_file('ex.wav')\n",
    "\n",
    "tf_audio, rate = tf.audio.decode_wav(audio,1)\n",
    "tf_audio = tf.squeeze(tf_audio,1)\n",
    "\n",
    "stft = tf.signal.stft(tf_audio,frame_length=48,frame_step=96,fft_length=48)\n",
    "a = datetime.datetime.now()\n",
    "\n",
    "spectrogram = tf.abs(stft)\n",
    "\n",
    "b = datetime.datetime.now()\n",
    "\n",
    "delta = b-a\n",
    "print(\"The total time is:\", (delta.total_seconds() * 1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd024c2-e8a2-4066-a7d5-41886bac6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.09202214e-04 3.51020244e-05 6.01649153e-05 ... 5.81319591e-06\n",
      "  3.05315079e-05 5.37591768e-06]\n",
      " [1.36416274e-04 5.45332696e-05 5.59677537e-05 ... 1.73576609e-05\n",
      "  1.64943012e-05 4.38441421e-05]\n",
      " [1.21128134e-04 5.08614503e-05 3.75189920e-05 ... 3.15201432e-05\n",
      "  2.57155643e-05 1.65582169e-05]\n",
      " ...\n",
      " [1.06530577e-04 8.01821443e-05 5.29719327e-05 ... 4.11437250e-05\n",
      "  6.23723754e-05 8.23469145e-06]\n",
      " [1.28837404e-04 5.69865297e-05 5.38902459e-05 ... 6.55624390e-05\n",
      "  2.95024256e-05 1.17306845e-05]\n",
      " [1.16351213e-04 5.20606227e-05 1.28945940e-05 ... 1.00783782e-05\n",
      "  5.09405618e-05 3.65012202e-05]], shape=(500, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d0dda9-228a-401b-bd32-292aa6c5eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_str = tf.io.serialize_tensor(tf_audio)\n",
    "tf.io.write_file('audio_str',audio_str,name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436e2ad2-bb6e-4f3b-a904-8ba184d049e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192014"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('audio_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05dd837a-14b6-4849-9277-53893e0af77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, audio = wavfile.read('no_01.wav')\n",
    "audio = signal.resample_poly(audio, 1, 3)\n",
    "audio = audio.astype(np.int16)\n",
    "wavfile.write(\"no_01_res.wav\",16000,audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203a1d09-f610-44ec-b615-852730407a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = tf.io.read_file('no_01_res.wav')\n",
    "\n",
    "tf_audio, rate = tf.audio.decode_wav(audio,1)\n",
    "tf_audio = tf.squeeze(tf_audio,1)\n",
    "\n",
    "stft = tf.signal.stft(tf_audio,frame_length=48,frame_step=960,fft_length=49)\n",
    "\n",
    "spectrogram = tf.abs(stft)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9b46c4-d663-42c6-9186-a9ab617f4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manage the spectrogram as image\n",
    "\n",
    "image = tf.transpose(spectrogram)\n",
    "image = tf.expand_dims(image, -1)\n",
    "image = tf.math.log(image + 1.e-6)\n",
    "\n",
    "#Min max normalization\n",
    "min_ = tf.reduce_min(image)\n",
    "max_ = tf.reduce_max(image)\n",
    "image = (image - min_) / (max_ - min_)\n",
    "image = image * 255.\n",
    "\n",
    "image = tf.cast(image, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de91884a-6ac0-4ebe-8beb-014310ccb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.io.encode_png(image, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a04c8c6c-68d6-460a-92fa-1e1926556efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.write_file('spec.png',img,name = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026fc2a-72a4-42ed-8a58-f95f29545164",
   "metadata": {},
   "source": [
    "## Ex.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196b2f55-2297-4539-8fab-4a3dedeb86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_str = tf.io.parse_tensor(audio_str,tf.float32, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bcaa1-7fcb-4d34-ae22-a70265770e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rivedere i parametri, studiare letteratura\n",
    "num_spectrogram_bins = spectrogram.shape[-1] \n",
    "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(#16000)\n",
    "mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1) \n",
    "mel_spectrogram.set_shape(spectrogram.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:])) \n",
    "log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c5afa-79d4-491a-9df2-c3f131be4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = tf.signal.mfccs_from_log_mel_spectrograms( log_mel_spectrogram)[..., :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddcf8f-a339-4d28-af0e-aeb6492a9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.write_file('mfcss',mfccs,name = None)\n",
    "os.path.getsize('mfccs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53052f3-5430-46e6-9e8b-fe8c1f5f8b8e",
   "metadata": {},
   "source": [
    "## Ex.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a00548b-0d7d-43e8-8bf8-16720805478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prova = audio = tf.io.read_file('img_prova.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb92012-2ac5-49cf-a010-75264c9666af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_img = tf.io.decode_jpeg(img_prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e679ab26-ad80-4821-bea9-8cb8cb9c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_img_cropped = tf.image.crop_to_bounding_box(tf_img,0,0,168,168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "303503b7-14c4-48a5-829f-cc342c4e17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.011153\n"
     ]
    }
   ],
   "source": [
    "a = datetime.datetime.now()\n",
    "\n",
    "tf_img_resized = tf.image.resize (tf_img,[224,224])\n",
    "\n",
    "b = datetime.datetime.now()\n",
    "delta = b-a\n",
    "print(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "361dd352-b6d3-4aaf-8f3f-4d801f4cc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_final = tf.cast(tf_img_resized, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01eb7741-faf5-43f3-83c0-f0c9eb94c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_final = tf.io.encode_png(img_final, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f05ff4d-bfd6-4f27-9b0e-62b6a50479ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.write_file('img_final.png',img,name = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
